{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "- Vectorise past data list info\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-703bd2959309>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0mabc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_cols\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as datetime\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "path = '../data_20161116/'\n",
    "train = pd.read_csv(path+'train.csv', parse_dates = ['dt_prediction_date', 'dt_target_date', 'dt_flight_date'])\n",
    "test = pd.read_csv(path+'test.csv', parse_dates = ['dt_prediction_date', 'dt_target_date', 'dt_flight_date'])\n",
    "\n",
    "target_cols = ['num_pax_000_014_mins_before_sdt', 'num_pax_015_029_mins_before_sdt',\n",
    "     'num_pax_030_044_mins_before_sdt', 'num_pax_045_059_mins_before_sdt',\n",
    "     'num_pax_060_074_mins_before_sdt', 'num_pax_075_089_mins_before_sdt',\n",
    "     'num_pax_090_104_mins_before_sdt', 'num_pax_105_119_mins_before_sdt',\n",
    "     'num_pax_120_134_mins_before_sdt', 'num_pax_135_149_mins_before_sdt',\n",
    "     'num_pax_150_164_mins_before_sdt', 'num_pax_165_179_mins_before_sdt',\n",
    "     'num_pax_180_194_mins_before_sdt', 'num_pax_195_209_mins_before_sdt',\n",
    "     'num_pax_210_224_mins_before_sdt', 'num_pax_225_239_mins_before_sdt',\n",
    "     'num_pax_240plus_mins_before_sdt']\n",
    "\n",
    "\n",
    "# Delete for model simplicity\n",
    "del train[\"cat_i_airport\"]\n",
    "del train[\"cat_i_city\"]\n",
    "\n",
    "# We will predict on this sample\n",
    "target_rows = train[train[\"cat_case_type\"]==\"Target\"]\n",
    "sample = target_rows.sample(n=int(len(target_rows)/100.0),random_state=42)\n",
    "# Remove these boyos from the training set\n",
    "rows = sample.index.values\n",
    "train = train.drop(rows)\n",
    "\n",
    "########################################################\n",
    "# 3. Define functions which we will use later in the script\n",
    "########################################################\n",
    "def check_for_negatives_in_pred(df_pred, l_cols_to_range_over):\n",
    "    '''A negative number of passengers turning up in a 15 minute window is not valid, so we set any negatives predictions to zero'''\n",
    "    df_pred[df_pred[l_cols_to_range_over] < 0] = 0\n",
    "    return df_pred\n",
    "\n",
    "def calculate_score(df_target_cases, df_predictions):\n",
    "    '''Root-mean-squared error is the chosen error metric. This function calculates and returns the root-mean-squared error'''\n",
    "    f_rmse = np.sqrt(mean_squared_error(df_target_cases, df_predictions))\n",
    "    return f_rmse\n",
    "\n",
    "def func(x,df):\n",
    "    \"\"\"\n",
    "    Predict on inputted row \"x\" using either past Expl data if available,\n",
    "    or KNN based on permitted past data if not.\n",
    "    \"\"\"\n",
    "    #    print(x[\"dt_prediction_date\"])\n",
    "    \n",
    "    ## If there's allowed Expl. data for the same flight, just use the mean values\n",
    "    expl_avail = df[df[\"id\"] == x[\"id\"]]\n",
    "    if len(expl_avail) > 0:\n",
    "        expl_avail = expl_avail[target_cols].mean(axis=0).astype(int)\n",
    "        return expl_avail\n",
    "        \n",
    "    ## If no historical data do a KNN model...\n",
    "    else:\n",
    "        # filter by past dates\n",
    "        permitted_data = df[df[\"dt_prediction_date\"]<=x[\"dt_prediction_date\"]]\n",
    "        # filter by allowed model\n",
    "        permitted_data = df[df[\"s_model_type\"] == x[\"s_model_type\"]]\n",
    "        \n",
    "        # now we can predict on the permitted data\n",
    "        #temp_df = clean(df.copy())\n",
    "        # Do some Cleaning\n",
    "        \n",
    "        \n",
    "        ## Need to first attach X_train and X_pred and transform/delete/encode consistently\n",
    "        Y_train = np.array(permitted_data[target_cols])\n",
    "        X_train = permitted_data[[col for col in permitted_data.columns.values if col not in target_cols]]\n",
    "        \n",
    "        #Y_pred = x[target_cols]\n",
    "        X_pred = x[[col for col in permitted_data.columns.values if col not in target_cols]]     \n",
    "        \n",
    "        \n",
    "        ## Now transform\n",
    "        temp_df = X_train.append(X_pred)\n",
    "        \n",
    "        categoricals = ['cat_sdt_hour',\n",
    "                    #'cat_i_airport', 'cat_i_city',\n",
    "                    'cat_destination_group_id', 'cat_longhaul_ind',\n",
    "                   \"cat_flight_class_type_id\"]\n",
    "\n",
    "        ordinals = [col for col in temp_df.columns.values if \"ord\" in col]\n",
    "\n",
    "        dates = ['num_flight_year', 'num_flight_month', 'num_flight_weekofyear', 'num_flight_dayofweek']\n",
    "\n",
    "        numericals = [feat for feat in temp_df.select_dtypes(include=[\"int\",\"float\"]).columns.values\n",
    "                      if feat not in dates+ordinals+categoricals]\n",
    "\n",
    "        ##########################\n",
    "        # Change Cat Departure Time to 3 categories\n",
    "        ##########################\n",
    "\n",
    "        def time_binner(y):\n",
    "            if y < 3 or y >= 19:\n",
    "                return \"Late\"\n",
    "            elif y >= 4 and y<= 11: \n",
    "                return \"Day\"\n",
    "            else:\n",
    "                return \"Morning\"\n",
    "\n",
    "        temp_df[\"cat_sdt_hour\"] = temp_df[\"cat_sdt_hour\"].apply(time_binner)\n",
    "\n",
    "        ##############\n",
    "        # Perform one hot encoding on the categorical features\n",
    "        ###############\n",
    "        for cat in categoricals[:]:\n",
    "            dummies = pd.get_dummies(temp_df[cat])\n",
    "            dummies.columns = [str(col_name) + \"_\" + cat for col_name in dummies.columns.values]            \n",
    "            temp_df = temp_df.drop(cat,axis=1)\n",
    "            temp_df = temp_df.join(dummies)\n",
    "        \n",
    "        \n",
    "        # kill these for model simplicity\n",
    "        cols_to_delete = [\n",
    "                          \"id\",\n",
    "                          'dt_prediction_date',\n",
    "                          'dt_target_date',\n",
    "                          's_model_type',\n",
    "                          'cat_case_type',\n",
    "                          'cat_i_flightno',\n",
    "                          'dt_flight_date',\n",
    "                          'cat_s_plane_capacity',\n",
    "                         ]\n",
    "\n",
    "        temp_df = temp_df.drop(cols_to_delete,axis=1)\n",
    "        \n",
    "        columns_to_keep = list(temp_df.columns.values)\n",
    "        \n",
    "#         print(x[[\"id\",\"s_model_type\"]])\n",
    "#         stop\n",
    "        #print(x[[\"id\",\"s_model_type\"]])\n",
    "        #print([col for col in x.index if col not in cols_to_delete])\n",
    "#        x = x.loc[[col for col in x.index if col not in target_cols]]\n",
    "#        x = x.loc[[col for col in x.index if col not in cols_to_delete]]\n",
    "     \n",
    "#         Y_train = np.array(temp_df[target_cols])\n",
    "#         X_train = (temp_df[[col for col in temp_df.columns.values if col not in target_cols]])\n",
    "# #         print(X_train.columns.values)\n",
    "# #         print(x.index)\n",
    "#         X_train = np.array(X_train)\n",
    "    \n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        #minmax_scale = min_max_scaler.fit(temp_df\n",
    "#        print(columns_to_keep)\n",
    "        temp_df[columns_to_keep] = min_max_scaler.fit_transform(temp_df[columns_to_keep])\n",
    "        \n",
    "        x = np.array(temp_df.iloc[-1])\n",
    "        X_train = np.array(temp_df.iloc[:-1])\n",
    "        \n",
    "        \n",
    "        neigh = KNeighborsRegressor(n_neighbors=3)\n",
    "        neigh.fit(X_train, Y_train)\n",
    "        \n",
    "#         X_test = x\n",
    "#         X_test = minmax_scale.transform(X_test)\n",
    "#         print(X_test)\n",
    "        \n",
    "        Y_pred = neigh.predict(x)\n",
    "       # print(len((Y_pred).flatten()))\n",
    "       # print(df.columns.values)\n",
    "        return pd.Series(Y_pred.flatten(),index=pd.Series(target_cols))\n",
    "    \n",
    "    #return np.array(permitted_data.index).flatten()\n",
    "\n",
    "abc = sample\n",
    "print(len(sample))\n",
    "stop\n",
    "prev = (np.array(abc[target_cols]))\n",
    "abc[target_cols] = abc.apply(lambda row : func(row,train),axis=1)\n",
    "print(abc)\n",
    "now = (np.array(abc[target_cols]))\n",
    "print(calculate_score(prev,now))\n",
    "#print(sample[\"past indices\"])\n",
    "\n",
    "# for i, row in sample.iterrows():\n",
    "#     print(row)\n",
    "#     day = row[\"dt_prediction_date\"]\n",
    "#     past_data = train[train[\"dt_prediction_date\"]<=day]\n",
    "#     print(len(past_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
